{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aerial Scene Classification with EfficientNet-B0\n",
        "Using Custom Dataset and Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3XbVWSS6pSHq",
        "outputId": "34ebdf1a-c224-4aa5-ffaa-4c0a1ee023fe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Label-Index Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def label_index(train_csv, test_csv):\n",
        "\n",
        "\n",
        "    train_data = pd.read_csv(train_csv)\n",
        "    test_data = pd.read_csv(test_csv)\n",
        "\n",
        "\n",
        "    train_label = train_data['label'].unique().tolist()\n",
        "\n",
        "    test_label = test_data['label'].unique().tolist()\n",
        "\n",
        "\n",
        "    labels = list(set(train_label + test_label))\n",
        "    labels.sort()  \n",
        "\n",
        "\n",
        "    li_dir = {label: index for index, label in enumerate(labels)}\n",
        "    il_dir = {index: label for label, index in li_dir.items()}\n",
        "\n",
        "    print(f\"{len(labels)} categories found: {labels}\")\n",
        "    return li_dir, il_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class intial_dataset(Dataset):\n",
        "    def __init__(self, file_path, li_dir, preprocess=None, root_path=None):\n",
        "        self.file_data = pd.read_csv(file_path)\n",
        "        self.li_dir = li_dir\n",
        "        self.preprocess = preprocess\n",
        "        self.root_path = root_path\n",
        "\n",
        "      \n",
        "        self.image_paths = self.file_data['image_path'].values\n",
        "        self.label_names = self.file_data['label'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_data)        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      \n",
        "        image_path = self.image_paths[index]\n",
        "        label_name = self.label_names[index]\n",
        "        label = self.li_dir[label_name]\n",
        "\n",
        "    \n",
        "        if self.root_path:\n",
        "            img_path = os.path.join(self.root_path, image_path)\n",
        "        else:\n",
        "            img_path = image_path\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.preprocess:\n",
        "            image = self.preprocess(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, test_loader, device, epochs=5):\n",
        "  \n",
        "    train_losses,  test_losses = [], []\n",
        "    train_acc_list, test_acc_list = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()           \n",
        "        train_loss = 0.0        \n",
        "        train_correct_num = 0   \n",
        "        train_total_num = 0\n",
        "\n",
        "       \n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)       \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)      \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)        \n",
        "            train_correct_num += (predicted == labels).sum().item()\n",
        "            train_total_num += labels.size(0)\n",
        "\n",
        "       \n",
        "        epoch_train_loss = train_loss / train_total_num\n",
        "        epoch_train_acc = train_correct_num / train_total_num\n",
        "\n",
        "        \n",
        "        model.eval()            \n",
        "        test_loss = 0.0        \n",
        "        test_correct_num = 0\n",
        "        test_total_num = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)       \n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)       \n",
        "\n",
        "                test_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)       \n",
        "                test_correct_num += (predicted == labels).sum().item()\n",
        "                test_total_num += labels.size(0)\n",
        "\n",
        "        \n",
        "        epoch_test_loss = test_loss / test_total_num\n",
        "        epoch_test_acc = test_correct_num / test_total_num\n",
        "\n",
        "       \n",
        "        train_losses.append(epoch_train_loss)\n",
        "        test_losses.append(epoch_test_loss)\n",
        "        train_acc_list.append(epoch_train_acc)\n",
        "        test_acc_list.append(epoch_test_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, \"\n",
        "              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.4f}\")\n",
        "\n",
        "    return train_losses, test_losses, train_acc_list, test_acc_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Data and Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    train_csv = 'COMP9517/augmented_train.csv'\n",
        "    test_csv = 'COMP9517/test.csv'\n",
        "    li_dir, il_dir = label_index(train_csv, test_csv)\n",
        "\n",
        "   \n",
        "    train_processed = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    test_processed = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "  \n",
        "    train_dataset = intial_dataset(\n",
        "        file_path=train_csv,\n",
        "        li_dir=li_dir,\n",
        "        preprocess=train_processed,\n",
        "        root_path='COMP9517'\n",
        "    )\n",
        "    test_dataset = intial_dataset(\n",
        "        file_path=test_csv,\n",
        "        li_dir=li_dir,\n",
        "        preprocess=test_processed,\n",
        "        root_path='COMP9517'\n",
        "    )\n",
        "\n",
        "  \n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Number of training samples: {len(train_dataset)} Number of test samples: {len(test_dataset)}\")\n",
        "    num_classes = len(li_dir)       \n",
        "    print(\"Total number of categories:\", num_classes)\n",
        "\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  \n",
        "    model = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "   \n",
        "    model.classifier[1] = nn.Linear(1280, num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)       \n",
        "\n",
        " \n",
        "    EPOCHS = 5\n",
        "    train_losses, test_losses, train_acc, test_acc = train_model(\n",
        "        model, criterion, optimizer, train_loader, test_loader, device, epochs=EPOCHS\n",
        "    )\n",
        "\n",
        "  \n",
        "   \n",
        "    plt.figure()\n",
        "    plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, EPOCHS+1), test_losses, label='Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training & Testing Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, EPOCHS+1), train_acc, label='Train Acc')\n",
        "    plt.plot(range(1, EPOCHS+1), test_acc, label='Test Acc')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training & Testing Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        " \n",
        "    model.eval()\n",
        "    predict_labels = []     \n",
        "    true_labels = []             \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predict_labels.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        " \n",
        "    labels_str = [il_dir[x] for x in true_labels]\n",
        "    preds_str = [il_dir[x] for x in predict_labels]\n",
        "\n",
        "    \n",
        "    print(\"\\n************ Classification Report ************\")\n",
        "    print(classification_report(labels_str, preds_str))\n",
        "\n",
        " \n",
        "    matrix = confusion_matrix(labels_str, preds_str)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d',\n",
        "                xticklabels=sorted(li_dir.keys()),\n",
        "                yticklabels=sorted(li_dir.keys()))\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
